---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I'm Yujia Liu, an HCI student researcher passionate about Human-AI Interaction and Fabrication. Currently, I'm pursuing my M.A. in Information Art and Design at the Future Lab of Tsinghua University, under the advisory of Prof. [Yingqing Xu](https://thfl.tsinghua.edu.cn/en/yjdw/yjtd/xyq/index.htm) and Prof. [Chun Yu](https://pi.cs.tsinghua.edu.cn/lab/people/ChunYu/). 

My academic journey began with undergraduate degrees in Automation Engineering and Industrial Design, laying a dual foundation that marries technical precision with aesthetic innovation. My work embodies this cross-disciplinary fusion, particularly evident in projects ranging from AR-enhanced smart mirrors, LLM-based digital well-being management, to 3D LEGO design generations. Each project reflects my commitment to leveraging a blend of engineering precision and design sensitivity, aiming to create technologies that are not only efficient and functional but also accessible and engaging for users.

In spare time I am also a vlogger & content creator on [Xiaohongshu](https://www.xiaohongshu.com/user/profile/5ad8bc90e8ac2b398c6ac4a1) with ~100k subscribers. 

I'm now looking for 2024 summer research opportunities. A complete version of my CV is available [HERE](https://yujia-l.github.io/cv.pdf).

# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">In submission to CHI'25</div><img src='images/proj/3DMirrorcle.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[3D-Mirrorcle: Bridging the Virtual and Real through Depth Alignment in Smart Mirror Systems](https://yujia-l.github.io/3DMirrorcle.pdf)

**Yujia Liu**, Qi Xin, Chenzhuo Xiang, Yu Zhang, Yingqing Xu.
- TLDR: An innovative smart mirror system integrating AR with real-world reflections, addressing depth disparity via a lenticular grating setup, with real-time image adjustment and position adaptation algorithms to align AR content with the user's depth perception and enhance interaction realism. Demonstrated through a makeup application prototype with significant improvements in accuracy (11.1% ‚Üë), task completion time (47.9% ‚Üì), and user satisfaction (44.4% ‚Üë) compared to the existing systems.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">In submission to CHI'25</div><img src='images/proj/BrickSmart.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
  
[BrickSmart: Leveraging Generative AI to Support Children's Spatial Language Learning in Family Block Play](https://yujia-l.github.io/BrickSmart.pdf)

**Yujia Liu***, Siyu Zha*, Yuewen Zhang, Yanjin Wang, Yangming Zhang, Qi Xin, Lunyiu Nie, Chao Zhang, Yingqing Xu.
- TLDR: A mobile application that leverages LLMs for generating dynamic, personalized persuasive content to mitigate problematic smartphone use for digital well-being. Effectiveness validated via a 5-week field trial with 25 participants, showing significant improvements in intervention acceptance (17.8-22.5% ‚Üë) and reductions in smartphone usage frequency (12.1-14.4% ‚Üì).
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">In submission to CHI'25</div><img src='images/proj/Mentigo.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
  
[Mentigo: An Intelligent Agent for Mentoring Students in the Creative Problem Solving Process](https://yujia-l.github.io/Mentigo.pdf)

Siyu Zha*, **Yujia Liu***, Chengbo Zheng, Jiaqi Xu, Fuze Yu, Jiangtao Gong, Yingqing Xu.
- TLDR: A mobile application that leverages LLMs for generating dynamic, personalized persuasive content to mitigate problematic smartphone use for digital well-being. Effectiveness validated via a 5-week field trial with 25 participants, showing significant improvements in intervention acceptance (17.8-22.5% ‚Üë) and reductions in smartphone usage frequency (12.1-14.4% ‚Üì).
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">In submission to CHI'25</div><img src='images/proj/Xstrings.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
  
[Xstrings: 3D printing cable-driven mechanism for actuation, deformation, and manipulation](https://yujia-l.github.io/Xstrings.pdf)

Jiaji Li, Shuyue Feng, Maxine Alexandra Perroni-Scharf, **Yujia Liu**, Emily Guan, Guanyun Wang, Stefanie Mueller. 
- TLDR: A mobile application that leverages LLMs for generating dynamic, personalized persuasive content to mitigate problematic smartphone use for digital well-being. Effectiveness validated via a 5-week field trial with 25 participants, showing significant improvements in intervention acceptance (17.8-22.5% ‚Üë) and reductions in smartphone usage frequency (12.1-14.4% ‚Üì).
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CHI'24</div><img src='images/proj/MindShift.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
  
[MindShift: Leveraging Large Language Models for Mental-States-Based Problematic Smartphone Use Intervention](https://dl.acm.org/doi/pdf/10.1145/3613904.3642790)

Ruolan Wu, Chun Yu, Xiaole Pan, **Yujia Liu**, Ningning Zhang, Yue Fu, Yuhan Wang, Zhi Zheng, Li Chen, Qi-aolei Jiang, Xuhai Xu, Yuanchun Shi.
- TLDR: A mobile application that leverages LLMs for generating dynamic, personalized persuasive content to mitigate problematic smartphone use for digital well-being. Effectiveness validated via a 5-week field trial with 25 participants, showing significant improvements in intervention acceptance (17.8-22.5% ‚Üë) and reductions in smartphone usage frequency (12.1-14.4% ‚Üì).
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">UIST'24 Poster</div><img src='images/proj/KeyFlow.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[KeyFlow: Acoustic Motion Sensing for Cursor Control on Any Keyboard](https://yujia-l.github.io/KeyFlow.pdf)

**Yujia Liu***, Qihang Shan*, Zhihao Yao, Qiuyu Lu.
- TLDR: A mobile application that leverages LLMs for generating dynamic, personalized persuasive content to mitigate problematic smartphone use for digital well-being. Effectiveness validated via a 5-week field trial with 25 participants, showing significant improvements in intervention acceptance (17.8-22.5% ‚Üë) and reductions in smartphone usage frequency (12.1-14.4% ‚Üì).
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">UIST'24 Demo</div><img src='images/proj/FlexEOP.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[FlexEOP: Flexible Shape-changing Actuator using Embedded Electroosmotic Pumps](https://yujia-l.github.io/FlexEOP.pdf)

Tianyu Yu, Yang Liu, **Yujia Liu**, Qiuyu Lu, Teng Han, Haipeng Mi.
- TLDR: A mobile application that leverages LLMs for generating dynamic, personalized persuasive content to mitigate problematic smartphone use for digital well-being. Effectiveness validated via a 5-week field trial with 25 participants, showing significant improvements in intervention acceptance (17.8-22.5% ‚Üë) and reductions in smartphone usage frequency (12.1-14.4% ‚Üì).
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">UbiComp'24 Workshop</div><img src='images/proj/<MoreThanShapes>.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[More Than Shapes: Exploring the Tactile Parameters of Art Appreciation for the Visually Impaired](https://dl.acm.org/doi/pdf/10.1145/3675094.3678391)

MingYu Cui, Chao Yuan, **Yujia Liu**, Yingying Zheng.
- TLDR: A mobile application that leverages LLMs for generating dynamic, personalized persuasive content to mitigate problematic smartphone use for digital well-being. Effectiveness validated via a 5-week field trial with 25 participants, showing significant improvements in intervention acceptance (17.8-22.5% ‚Üë) and reductions in smartphone usage frequency (12.1-14.4% ‚Üì).
</div>
</div>

# üóÇÔ∏è Projects 

<div class='paper-box'><div class='paper-box-image'><div><img src='images/proj/lego.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**3D LEGO Designs Generation and Structural Optimization with Generative Models**
- TLDR: A 3D model generation system combining generative models, stability prediction, and optimization to repurpose unused LEGO bricks, fostering creativity and sustainability. Achieved up to a 42.7% increase in design diversity, a 13.9% increase in user engagement, and a 6.9% improvement in user satisfaction, demonstrating significant advances in interactive design and sustainability.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><img src='images/proj/music_light.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**Adaptive Music and Lighting Systems for Emotional Well-being**
- TLDR: A smart home system that dynamically adjusts music and lighting to nurture inhabitants' emotional well-being, leveraging environmental and color psychology with MER. Capable of responding to and anticipating user emotions and preferences, with a 22.1% enhancement in satisfaction according to a user experience study.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><img src='images/proj/smart_editing.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**Automated Video Editing with Semantic Analysis and Aesthetic Evaluation**
- TLDR: An intelligent video editing framework that integrates video semantic analysis and aesthetic evaluation to com-bine AI with user-centered designs for automating video production tasks. Achieved a 62.5% reduction in editing time, demonstrating the frame-work's effectiveness in improving editing efficiency and output quality.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><img src='images/proj/phone_color.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**Adaptive Image Color Enhancement Across Diverse Displays**
- TLDR: Collected color preferences in digital media via a comprehensive user survey with 89 participants and an expert interview with 24 photographers to identify color preferences across image types & user demographics. Developed a system based on DeepLPF for adaptive image color enhancement under mobile photography scenar-ios, significantly enhanced user satisfaction (12% ‚Üë) in an offline evaluation with 89 participants.
</div>
</div>

# üìñ Educations
- *2022.09 - Now*, Tsinghua University, M.A. in Information Art and Design.
- *2017.08 - 2022.07*, Tsinghua University, B.Eng. in Automation Engineering & B.A. in Industrial Design.

# üíª Internship Experience
- *2021.8 - Now*, Research Assistant @ Future Lab, Tsinghua University.
- *2024.6 - Now*, Visiting Student @ HCI Engineering Group, CSAIL, MIT.
- *2022.10 - 2023.6*, Research Assistant @ Pervasive Interaction Laboratory, Tsinghua University.
- *2021.07 - 2021.10*, Product Manager Intern @ Huawei, ID/UX Design Group, Cyberverse Product Line.
- *2020.06 - 2020.08*, Algorithm Engineer Intern @ Beijing Ewaybot Technology, Robot Navigation Group.

